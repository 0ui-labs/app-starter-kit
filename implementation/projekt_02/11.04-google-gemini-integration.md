# 11.04 Google Gemini Integration

## Ziel
Implementierung des Google Gemini Providers mit Unterstützung für Gemini Pro, Gemini Pro Vision und Embeddings.

## Umfang
- Google Generative AI SDK integration
- Gemini model support
- Multi-modal capabilities (text + images)
- Safety settings configuration
- Function calling support

## Tasks

### 1. Package Dependencies
```json
// packages/ai-adapter/package.json
{
  "dependencies": {
    "@google/generative-ai": "^0.x.x"
  }
}
```

### 2. Google Gemini Provider Implementation
```typescript
// packages/ai-adapter/src/providers/google.ts
import { GoogleGenerativeAI, GenerativeModel } from '@google/generative-ai';
import { BaseAIProvider } from '../base-provider';

export class GoogleProvider extends BaseAIProvider {
  private genAI: GoogleGenerativeAI;
  private model: GenerativeModel;
  
  async initialize(config: GoogleConfig): Promise<void> {
    this.genAI = new GoogleGenerativeAI(config.apiKey);
    
    // Default model configuration
    this.model = this.genAI.getGenerativeModel({
      model: config.defaultModel || 'gemini-pro',
      safetySettings: config.safetySettings,
      generationConfig: {
        temperature: config.temperature,
        topK: config.topK,
        topP: config.topP,
        maxOutputTokens: config.maxOutputTokens,
      },
    });
    
    this.config = config;
  }
  
  async complete(request: CompletionRequest): Promise<CompletionResponse> {
    const model = this.getModel(request.model);
    
    // Convert messages to Gemini format
    const chat = model.startChat({
      history: this.formatChatHistory(request.messages),
      generationConfig: {
        temperature: request.temperature,
        maxOutputTokens: request.maxTokens,
      },
    });
    
    const result = await chat.sendMessage(
      this.getLastUserMessage(request.messages)
    );
    
    return this.formatResponse(result.response);
  }
  
  async stream(request: CompletionRequest): AsyncIterableIterator<StreamChunk> {
    const model = this.getModel(request.model);
    
    const chat = model.startChat({
      history: this.formatChatHistory(request.messages),
      generationConfig: {
        temperature: request.temperature,
        maxOutputTokens: request.maxTokens,
      },
    });
    
    const result = await chat.sendMessageStream(
      this.getLastUserMessage(request.messages)
    );
    
    for await (const chunk of result.stream) {
      yield this.formatStreamChunk(chunk);
    }
  }
  
  async embed(text: string): Promise<number[]> {
    const model = this.genAI.getGenerativeModel({
      model: 'embedding-001',
    });
    
    const result = await model.embedContent(text);
    return result.embedding.values;
  }
}
```

### 3. Message Format Conversion
```typescript
private formatChatHistory(messages: Message[]): GeminiContent[] {
  const history: GeminiContent[] = [];
  
  for (const msg of messages) {
    if (msg.role === 'system') {
      // Gemini doesn't have system role, prepend to first user message
      continue;
    }
    
    history.push({
      role: this.mapRole(msg.role),
      parts: this.formatParts(msg),
    });
  }
  
  return history;
}

private formatParts(message: Message): Part[] {
  const parts: Part[] = [];
  
  // Text part
  if (message.content) {
    parts.push({ text: message.content });
  }
  
  // Image parts (for Gemini Pro Vision)
  if (message.images) {
    for (const image of message.images) {
      parts.push({
        inlineData: {
          mimeType: image.mimeType,
          data: image.data, // base64
        },
      });
    }
  }
  
  return parts;
}

private mapRole(role: string): 'user' | 'model' {
  return role === 'assistant' ? 'model' : 'user';
}
```

### 4. Safety Settings
```typescript
// packages/ai-adapter/src/providers/google-safety.ts
import { HarmCategory, HarmBlockThreshold } from '@google/generative-ai';

export const DEFAULT_SAFETY_SETTINGS = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
];

export function configureSafetySettings(level: 'strict' | 'moderate' | 'none') {
  switch (level) {
    case 'strict':
      return DEFAULT_SAFETY_SETTINGS.map(s => ({
        ...s,
        threshold: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
      }));
    case 'moderate':
      return DEFAULT_SAFETY_SETTINGS;
    case 'none':
      return DEFAULT_SAFETY_SETTINGS.map(s => ({
        ...s,
        threshold: HarmBlockThreshold.BLOCK_NONE,
      }));
  }
}
```

### 5. Function Calling Support
```typescript
private formatFunctions(tools?: Tool[]): FunctionDeclaration[] {
  if (!tools) return [];
  
  return tools.map(tool => ({
    name: tool.name,
    description: tool.description,
    parameters: {
      type: 'object',
      properties: tool.parameters.properties,
      required: tool.parameters.required,
    },
  }));
}

// Handle function call responses
private handleFunctionCalls(response: GenerateContentResponse): ToolCall[] {
  const functionCalls = response.functionCalls();
  if (!functionCalls) return [];
  
  return functionCalls.map(call => ({
    id: generateId(),
    name: call.name,
    arguments: call.args,
  }));
}
```

### 6. Model Configuration
```typescript
// packages/ai-adapter/src/providers/google-models.ts
export const GEMINI_MODELS = {
  'gemini-pro': {
    name: 'gemini-pro',
    contextWindow: 32768,
    maxOutput: 2048,
    supportsVision: false,
    supportsFunctions: true,
  },
  'gemini-pro-vision': {
    name: 'gemini-pro-vision',
    contextWindow: 16384,
    maxOutput: 2048,
    supportsVision: true,
    supportsFunctions: false,
  },
  'gemini-1.5-pro': {
    name: 'gemini-1.5-pro-latest',
    contextWindow: 1048576, // 1M tokens
    maxOutput: 8192,
    supportsVision: true,
    supportsFunctions: true,
  },
};
```

### 7. Error Handling
```typescript
protected handleGoogleError(error: any): never {
  if (error.message?.includes('SAFETY')) {
    throw new SafetyFilterError({
      provider: 'google',
      message: 'Content blocked by safety filters',
      details: error.safetyRatings,
    });
  }
  
  if (error.message?.includes('quota')) {
    throw new QuotaExceededError({
      provider: 'google',
      message: 'API quota exceeded',
    });
  }
  
  throw new AIProviderError({
    code: error.code || 'UNKNOWN',
    message: error.message,
    provider: 'google',
    retryable: this.isRetryableError(error),
  });
}
```

## Dateien zu erstellen/ändern
- `packages/ai-adapter/src/providers/google.ts` - Main implementation
- `packages/ai-adapter/src/providers/google-models.ts` - Model configurations
- `packages/ai-adapter/src/providers/google-safety.ts` - Safety settings
- `packages/ai-adapter/src/providers/google-types.ts` - Google specific types
- `packages/ai-adapter/package.json` - Add Google Generative AI dependency

## Akzeptanzkriterien
- [ ] Google Generative AI SDK korrekt integriert
- [ ] Gemini Pro und Gemini Pro Vision unterstützt
- [ ] Multi-modal input (Text + Bilder) funktioniert
- [ ] Safety settings konfigurierbar
- [ ] Function calling implementiert
- [ ] Embeddings funktionieren
- [ ] Streaming unterstützt
- [ ] Fehler werden korrekt behandelt
- [ ] Tests für alle Hauptfunktionen

## Abhängigkeiten
- Task 11.01 (Provider Abstraction) muss abgeschlossen sein
- Google API Key in environment variables
- @google/generative-ai npm package

## Geschätzter Aufwand
60-75 Minuten