# Sub-Task 13.03: AI Adapter Bridge

## Ziel
Implementierung einer Bridge zwischen unserem bestehenden AI Adapter und LlamaIndex, um doppelte Provider-Implementierungen zu vermeiden.

## Umfang
- AIAdapterLLM Klasse, die BaseLLM von LlamaIndex erweitert
- Integration mit bestehendem @starter-kit/ai-adapter
- Support für chat und streaming
- Metadata Configuration

## Implementierung

### 1. LLM Bridge (`src/llm-bridge.ts`)
- Erweitert `BaseLLM` von LlamaIndex
- Nutzt intern unseren `AIAdapter`
- Implementiert `chat()` und `streamChat()` Methoden
- Konfiguriert LLM Metadata

### 2. Features
- Provider-Agnostisch (openai, anthropic, google)
- Stream Support
- Nahtlose Integration mit bestehender AI Adapter Logik
- Wiederverwendung bestehender Konfiguration

## Erfolgskriterien
- [ ] AIAdapterLLM Klasse implementiert
- [ ] Integration mit AI Adapter funktioniert
- [ ] Chat und Stream Methoden implementiert
- [ ] TypeScript Types korrekt
- [ ] Keine Duplikation von Provider-Code

## Zeitschätzung: 10 Minuten